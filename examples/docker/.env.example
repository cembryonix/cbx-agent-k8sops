# =============================================================================
# Docker Container Settings (for app-in-docker.sh)
# =============================================================================

CONTAINER_NAME=k8sops-agent
IMAGE_NAME=ghcr.io/cembryonix/cbx-agent-k8sops:0.2.2

# K8SOps Agent - Environment Configuration
# Copy this file to .env and fill in your values
#
# IMPORTANT: Do not use inline comments!
# Docker --env-file does not strip them.

# =============================================================================
# LLM Provider - choose one and set its API key
# =============================================================================

# Options: anthropic, openai, ollama
LLM_PROVIDER=anthropic

# Anthropic
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx

# OpenAI (uncomment if using)
#OPENAI_API_KEY=sk-xxxxx

# Ollama (uncomment if using, no API key needed)
#OLLAMA_BASE_URL=http://host.docker.internal:11434

# =============================================================================
# Default LLM Settings
# =============================================================================

LLM_MODEL=claude-sonnet-4-5-20250929
LLM_TEMPERATURE=0.0

# =============================================================================
# MCP Server Connection
# =============================================================================

MCP_TRANSPORT=http
MCP_SERVER_URL=https://your-mcp-server.example.com
MCP_SSL_VERIFY=true

# =============================================================================
# Agent Memory - Storage Backend
# =============================================================================

# Memory backend type: memory, filesystem, or redis
# - memory: In-memory only, no persistence (default, for testing)
# - filesystem: Local JSONL files (for local development)
# - redis: Redis server (for production)
MEMORY_BACKEND=filesystem

# Filesystem path (used when MEMORY_BACKEND=filesystem)
# Default: ~/.k8sops
#MEMORY_FILESYSTEM_PATH=~/.k8sops

# Redis URL (required when MEMORY_BACKEND=redis)
#REDIS_URL=redis://localhost:6379

# Use shallow checkpointer (only stores latest state, not full history)
# Recommended for production to reduce memory usage
#MEMORY_SHALLOW=true

# =============================================================================
# Agent Memory - Long-term (optional, requires Redis)
# =============================================================================

# Enable long-term memory (learns from sessions, retrieves relevant context)
#MEMORY_LONG_TERM_ENABLED=true

# Embedding provider for semantic search
# Options: openai, ollama (Anthropic has no embeddings API)
#EMBEDDING_PROVIDER=openai

# Embedding model (defaults: openai=text-embedding-3-small, ollama=nomic-embed-text)
#EMBEDDING_MODEL=text-embedding-3-small

# Context window management
# Threshold (0.0-1.0) that triggers conversation summarization
#MEMORY_CONTEXT_THRESHOLD=0.75

# Maximum tokens before triggering summarization
#MEMORY_MAX_CONTEXT_TOKENS=100000

# Number of memories to retrieve per search
#MEMORY_MAX_MEMORIES=5

# =============================================================================
# Session Management (optional, requires filesystem or redis backend)
# =============================================================================

# Maximum number of chat sessions to keep per user
#MAX_SESSIONS=10

# User ID for session/memory namespace (use default when no auth)
#MEMORY_USER_ID=default

# =============================================================================
# Application Settings (optional)
# =============================================================================

# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

#K8SOPS_FRONTEND_PORT=3000
#K8SOPS_BACKEND_PORT=8000

