# values.yaml

# MCP Server inclusion flag
mcp_included: true

# Agent configuration
agent:
  replicaCount: 1
  
  image:
    repository: ghcr.io/vkuusk/cbx-agent-k8sops
    tag: "v0.1.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
  
  ingress:
    enabled: true
    className: nginx
    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: /
    host: cbx-agent-k8sops.yourdomain.com  # Change this to your domain
    path: /
    pathType: Prefix
  
  # Secret references - these secrets must exist before deployment
  secretReferences:
    openaiApiKey:
      secretName: "cbx-agent-k8sops-openai-key"
      secretKey: "api-key"
      namespace: "cbx-agents"
    anthropicApiKey:
      secretName: "cbx-agent-k8sops-anthropic-key"
      secretKey: "api-key"
      namespace: "cbx-agents"
  
  # Configuration files for .k8sops directory
  config:
    configYaml: |
      default_model: openai/gpt-4.1-nano
      temperature: 0.1
      providers:
        ollama:
          base_url: http://localhost:11434

    mcpConfigJson: |
      {
        "mcp_servers": {
          "k8s_mcp": {
            "url": "http://cbx-agent-k8sops-mcp-server:8080/mcp/",
            "transport": "streamable_http"
          }
        }
      }
  
  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 500m
      memory: 512Mi

# MCP Server dependency configuration
# This section configures the MCP server when deployed as a dependency
cbx-mcp-server-k8s:
  # Override MCP server values here if needed
  # Most values will use defaults from the MCP server chart
  ingress:
    host: cbx-mcp-k8s.yourdomain.com  # Change this to your domain

# Global settings
nodeSelector: {}
tolerations: []
affinity: {}

# Note: Both images are public on GHCR, no credentials needed
